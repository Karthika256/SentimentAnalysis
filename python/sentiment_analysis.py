# -*- coding: utf-8 -*-
"""Sentiment Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kJ932-b9Xl3aIejkxSWUkpn8lrdg2YFM

(Need to downgrade numpy to install scikit learn version 1.4.2 - required version for Streamlit)
"""

# 1. Downgrade numpy to a compatible version
!pip install numpy==1.26.4 --force-reinstall

# 2. Reinstall scikit-learn with compatible version
!pip install scikit-learn==1.4.2 --force-reinstall

# 3. Restart the kernel (Colab tip: this needs manual action)

#Confirm version
import sklearn
print(sklearn.__version__)

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import joblib

"""# Data Overview"""

# Load data
dataset = pd.read_csv("Restaurant_Reviews.tsv", sep='\t')

print(dataset.info())

print(dataset['Liked'].value_counts())

"""Findings
* The dataset contains 2 variables, a Review column and a Liked column (binary) to indicate if the review was good or bad.
* There are a total of 1000 records, 500 bad and 500 good reviews. No class imbalance observed.

# Data Pre-processing
"""

# Preprocess
vectorizer = CountVectorizer(lowercase=True,
                             stop_words='english',
                             strip_accents='ascii',
                             max_df=0.999)
X = vectorizer.fit_transform(dataset['Review']).toarray()
y = dataset['Liked']

"""Splitting dataset"""

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)

"""# Random Forest Model"""

# Train model
model = RandomForestClassifier(n_estimators=10, random_state=123)
model.fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

"""# Voting Classifier Model"""

from sklearn.ensemble import VotingClassifier

from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC

model1 = MultinomialNB()
model2 = LogisticRegression(max_iter=1000)
model3 = LinearSVC()

ensemble = VotingClassifier(estimators=[
    ('nb', model1),
    ('lr', model2),
    ('svc', model3)
], voting='hard')

ensemble.fit(X_train, y_train)
from sklearn.metrics import classification_report

#evaluate
y_pred = ensemble.predict(X_test)
print(classification_report(y_test, y_pred))

"""# Support Vector Machine"""

from sklearn.svm import LinearSVC

model = LinearSVC()
model.fit(X_train, y_train)

#evaluate
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

"""# Multinomial Naive Bayes"""

from sklearn.naive_bayes import MultinomialNB

model = MultinomialNB()
model.fit(X_train, y_train)

#evaluate
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

"""# Model Comparison

1. Random Forest
* Accuracy: 0.70
* F1-score:
 * Class 0: 0.71
 * Class 1: 0.70
* Weakest model — less balanced, lower performance on both classes

2. Voting Classifier
* Accuracy: 0.81
* F1-score:
 * Class 0: 0.79
 * Class 1: 0.83
* Top performer overall

3. Support Vector Machine (SVM)
* Accuracy: 0.77
* F1-score:
 * Class 0: 0.74
 * Class 1: 0.80
* Strong recall for class 1, but not as balanced as Voting Classifier

4. Multinomial Naive Bayes
* Accuracy: 0.80
* F1-score:
 * Class 0: 0.75
 * Class 1: 0.83
* Close second — great for class 1, weaker on class 0

In conclusion, while all models demonstrate reasonable performance, the Voting Classifier stands out as the most balanced and accurate, making it the best choice for the final model. It consistently achieves high scores across precision, recall, and F1 for both classes, indicating strong generalization and reliability.

# Saving the Model
"""

# Save the model and vectorizer
joblib.dump(ensemble, 'sentiment_model_1.pkl')
joblib.dump(vectorizer, 'vectorizer_1.pkl')